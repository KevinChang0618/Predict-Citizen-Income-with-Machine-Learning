---
title: '1'
author: "Jingyi Xu"
date: "3/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load and tidy the data 
```{r}
library(tidyverse)
adult<-read.table("adult.data", sep=",", stringsAsFactors = F, na.strings = "?")
colnames(adult)<-c("age","workclass","fnlwgt","eduaction","education_num","marital_status","occupation","relationship","race","sex","capital_gain","capital_loss","hours_per_week","native_country","income")
z = c()
for (i in 1:nrow(adult)){
  for (j in 1:15){
    if(adult[i,j]==" ?"){
      z = append(z,i)
      break
    }
  }
}

adult = adult[-z, ]
adult


mutate(adult, income = recode(income," <=50K"="1",
                              " >50K"="0")) -> adult

adult$income <- as.numeric(adult$income)
head(adult)

```

# logistic regression with variable selection
```{r}
full <- glm(income~.,data = adult,family = binomial(link=logit))

null <- glm(income~1,data = adult,family = binomial(link=logit))
step(null,scope = list(lower = null, upper = full), method = "forward")
```


# logistic regression with selecting final variables
```{r}
glm(formula = income ~ relationship + eduaction + capital_gain + 
    occupation + capital_loss + hours_per_week + age + sex + 
    marital_status + workclass + fnlwgt + race, 
    family = binomial(link=logit), data = adult) -> new.fit2
summary(new.fit2)
```

- After variable selection by using stepwise method, we choose relationship,eduaction, capital_gain, occupation, capital_loss, hours_per_week, age, sex, marital_status, workclass, fnlwgt, race for our predictors. Then we fit the logic regression model, the residual deviance is 19571 and AIC is 19683.

# Predict confuse matrix
```{r}
thresh <- 0.5
pred.probs <- predict(new.fit2, adult, type="response")
pred <- ifelse(pred.probs > thresh, 1, 0)
conf.mat <- table("Predicted"=pred, "Actual"=adult$income)
conf.mat

(4561+21021)/(4561+1633+2947+21021)
```

- The preditive accuracy is 84.8%.

# Cross-Validation
```{r}
library(boot)
loss = function(Y,p){ 
  return( mean( (Y==1 & p < 0.5) | (Y==0 & p >= 0.5) ) ) 
}
cv.error = cv.glm( adult, new.fit2 ,loss,K=10)
cv.error$delta[1]
```

- We use K-fold(K=10) method to do cross-validation for the model, the MSE of this logic regression model is 0.1528745.

# LDA classification
```{r}
attach(adult)
library(MASS)

table(adult$income)
c(7508,22654)/30162 # prior probability (0= 0.25/ 1= 0.75)

lda.fit = lda(income~ relationship + eduaction + capital_gain + 
                      occupation + capital_loss + hours_per_week + age + sex + 
                      marital_status + workclass + fnlwgt + race, 
                      data= adult, CV=TRUE)
data.frame(lda.fit$posterior, lda.fit$class)

yhat = lda.fit$class
table(yhat, income)

err.rate = mean(yhat!=income)
err.rate # lda error rate = 16.37159%
```

```{r}
# find best threshold 
err = rep(0,99)

set.seed(1)

for (i in 1:99){
lda.fit = lda(income~ relationship + eduaction + capital_gain + 
                      occupation + capital_loss + hours_per_week + age + sex + 
                      marital_status + workclass + fnlwgt + race, 
              data= adult, CV=TRUE, prior = c(i*0.01, 1-i*0.01)) # change prior
data.frame(lda.fit$posterior, lda.fit$class)

yhat = lda.fit$class

err[i] = mean(yhat!=income)
}

which.min(err)
err[25] #(0= 0.25/ 1= 0.75), error rate: 16.36828%
```
In LDA, we use relationship, eduaction, capital_gain, occupation, capital_loss, hours_per_week, age, sex, marital_status, workclass, fnlwgt, and race 12 predictors. Prior probability are 0(income < 50K)= 0.25 and 1(income >= 50K)= 0.75 and classification error rate is 16.39%. After tuning to find best threshold for prior probability, we get the result is almost match with origin.

# QDA
```{r}
attach(adult)
library(MASS)

table(adult$income)
c(7508,22654)/30162 # prior probability (0= 0.25/ 1= 0.75)
set.seed(1)
qda.fit = qda(income~ age+ education_num+ occupation+ race+ sex+ hours_per_week, 
                      data= adult, CV=TRUE)
# qda cannot run with using many predictors. i try to eliminate some predictors.

yhat = as.character(qda.fit$class)# find the NA value and delete them

a = which(is.na(yhat)==T)

length(yhat)
length(income)

yhat = yhat[-a]
income = income[-a]

table(yhat, income)
err.rate = mean(yhat!=income)
err.rate # qda error rate = 43.25%
```



```{r}
# find best threshold
err = rep(0,99)

set.seed(1)
for (i in 1:99){
adult2 = adult
attach(adult2)
qda.fit = qda(income~ age+ education_num+ occupation+ race+ sex+ hours_per_week, 
              data= adult2, CV=TRUE, prior = c(i*0.01, 1-i*0.01)) # change prior
#data.frame(qda.fit$posterior, qda.fit$class)

yhat = as.character(qda.fit$class)

a = which(is.na(yhat)==T)
yhat = yhat[-a]
income = adult2$income[-a]

err[i] = mean(yhat!=income)
}

which.min(err) # 0: 0.01/ 1:0.99
err[1] # err rate: 0.31
```

In QDA, at first, we use same predictors like LDA but it has something errors. So, we choose age, education_num, occupation, race, sex, and hours_per_week for our predictors. During QDA analysis it will cause some NA value so we would delete it, at preliminary modeling, our classification error rate is 43.25%. After tuning threshold, we find prior probability with 0(income < 50K)= 0.01 and 1(income >= 50K)= 0.99 have lowest classification rate 31.95%.

# KNN
```{r}

# change all column's type to numeric so that we can calculate distance for KNN.
adult$relationship = as.numeric(as.factor(adult$relationship))

adult$eduaction = as.numeric(as.factor(adult$eduaction))
adult$sex = as.numeric(as.factor(adult$sex))
adult$marital_status = as.numeric(as.factor(adult$marital_status))
adult$workclass = as.numeric(as.factor(adult$workclass))
adult$race = as.numeric(as.factor(adult$race))
adult$occupation = as.numeric(as.factor(adult$occupation))

adult$age = as.numeric(adult$age)
adult$fnlwgt = as.numeric(adult$fnlwgt)
adult$capital_gain = as.numeric(adult$capital_gain)
adult$capital_loss = as.numeric(adult$capital_loss)
adult$hours_per_week = as.numeric(adult$hours_per_week)

adult


```


```{r}
library(class)
n = length(adult$age)

set.seed(1)
z = sample(n, n/2) # 15081

xtrain = data.frame(adult$age[z], adult$workclass[z], adult$fnlwgt[z], adult$eduaction[z], adult$marital_status[z],
                    adult$occupation[z], adult$relationship[z], adult$race[z], adult$sex[z], adult$capital_gain[z],
                    adult$capital_loss[z], adult$hours_per_week[z])

xtest = data.frame(adult$age[-z], adult$workclass[-z], adult$fnlwgt[-z], adult$eduaction[-z], 
                   adult$marital_status[-z], adult$occupation[-z], adult$relationship[-z], 
                   adult$race[-z], adult$sex[-z], adult$capital_gain[-z], adult$capital_loss[-z],
                   adult$hours_per_week[-z])

ytrain= adult$income[z]
ytest= adult$income[-z]

yhat = knn(xtrain, xtest, ytrain, 10)

# test
knn(xtrain, data.frame("age"=52, "workclass"=5, "fnlwgt"=209642, "eduaction"=12,
                       "marital_status"= 3, "occupation"=4, "relationship"= 1,
                       "race"= 5, "sex"= 2, "capital_gain"= 0, "capital_loss"= 0,
                       "hours_per_week"= 45), ytrain, 1)

```

```{r}
# choose K
err.class = rep(0,100) # calculate error for each K

TPR = rep(0,100)
FPR = rep(0,100)

for (k in 1:100){
  yhat = knn(xtrain, xtest, ytrain, k)
  err.class[k] = mean(yhat != ytest)
  FPR[k] = sum(yhat==1 & ytest==0)/ sum(ytest==0) # false positive
  TPR[k] = sum(yhat==1 & ytest==1)/ sum(ytest==1) # true positive
}

k= 1:100
plot(k, err.class, type="b", lwd=5)

which.min(err.class) # K= 19
err.class[19] # 0.2033

```

- In KNN method, we use relationship, eduaction, capital_gain, occupation, capital_loss, hours_per_week, age, sex, marital_status, workclass, fnlwgt, and race 12 predictors to build our KNN model. We find that K= 19 has the lowest classification error rate 20.33%.


# Classification trees
```{r}
library(tidyverse)
adult<-read.table("adult.data", sep=",", stringsAsFactors = F, na.strings = "?")
colnames(adult)<-c("age","workclass","fnlwgt","eduaction","education_num","marital_status","occupation","relationship","race","sex","capital_gain","capital_loss","hours_per_week","native_country","income")
z = c()
for (i in 1:nrow(adult)){
  for (j in 1:15){
    if(adult[i,j]==" ?"){
      z = append(z,i)
      break
    }
  }
}

adult = adult[-z, ]
adult


mutate(adult, income = recode(income," <=50K"="1",
                              " >50K"="0")) -> adult

adult$income <- as.numeric(adult$income)
head(adult)
```

```{r}
library(tree)
table(adult$income)
```

```{r}
n = nrow(adult)
z = sample(n, n*0.8)

dat <- adult[, -5]
mod <- tree(as.factor(income)~ relationship+age+workclass+eduaction+fnlwgt+race+capital_gain+occupation+
              capital_loss +marital_status+hours_per_week+sex, dat, subset= z)
mod
```

```{r}
plot(mod, type="uniform")      
text(mod)
```

```{r}
summary(mod)
```

The misclassification rate of the trainng dataset is 0.193.


```{r}
preds = predict(mod, newdata= dat[-z,], type="class")
table(preds, dat[-z,]$income)       
```

```{r}
mean(preds!= dat[-z,]$income)
```

The misclassification rate of the test dataset is 0.184.

## Pruning
```{r}
cv=cv.tree(mod)
cv
```

```{r}
which.min(cv$dev) # real deviance
```

```{r}
cv$dev[1]
cv$size[1]
```

```{r}
plot(cv)
```

```{r}
tr.opt = prune.tree(mod, best= 5)
plot(tr.opt)
text(tr.opt)
summary(tr.opt)
```

Therefore, it can be found that 19.3% classification error rate after tuning the tree. In the original model, capital_gain, age, capital loss and hours per week influence people's income to the greatest extent. By optimizing the classification of the tree, there are still same predictors have most influence.

# Random Forest
```{r}
library(tidyverse)
adult<-read.table("adult.data", sep=",", stringsAsFactors = F, na.strings = "?")
colnames(adult)<-c("age","workclass","fnlwgt","eduaction","education_num","marital_status","occupation","relationship","race","sex","capital_gain","capital_loss","hours_per_week","native_country","income")
z = c()
for (i in 1:nrow(adult)){
  for (j in 1:15){
    if(adult[i,j]==" ?"){
      z = append(z,i)
      break
    }
  }
}

adult = adult[-z, ]
adult


mutate(adult, income = recode(income," <=50K"="1",
                              " >50K"="0")) -> adult

adult$income <- as.numeric(adult$income)
head(adult)
```


```{r}
n = nrow(adult)
z = sample(n, n*0.8)

ncol(adult)
```

```{r}
library(randomForest)
train_RF = randomForest(as.factor(income)~., data= adult[z,])
train_RF
```

```{r}
yhat = predict(train_RF, newdata= adult[-z,])

table(yhat, adult$income[-z])
mean(yhat!= adult[-z]$income) # testing classification error rate
```

# tuning
```{r}
p = ncol(adult) -1

ERRORRATE = rep(0,p) # p = 11 predictors. try every predictors to find the best random forest
optimaltrees = rep(0,p)

for(k in 1:p){
  train_RF = randomForest(as.factor(income)~., data= adult[z,], mtry= k)
  optimaltrees[k] = which.min(train_RF$err.rate) # In each variables selection, number with lowest error rate = optimal trees.
  
  train_RF = randomForest(as.factor(income)~., data= adult[z,], mtry= k, ntree= optimaltrees[k])
  yhat = predict(train_RF, newdata = adult[-z,])
  
  ERRORRATE[k] = mean(yhat!= adult$income[-z])
  #plot(train_RF$err.rate)
}
```

```{r}
which.min(ERRORRATE) # 3
```

```{r}
optimaltrees[2]
optimaltrees
```

```{r}
best_RF = randomForest(as.factor(income)~., data= adult[z,], mtry= 2, ntree= 1186) 
best_RF
# training error rate from 13.86% -> 13.91%
```

```{r}
yhat = predict(best_RF, newdata= adult[-z,], type="class")

table(yhat, adult$income[-z])
mean(yhat!= adult$income[-z]) 
# testing error rate from 34.96% -> 14.29%
```

```{r}
importance(best_RF) 
varImpPlot(best_RF)
```


